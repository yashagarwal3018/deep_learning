{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4332812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import pydicom \n",
    "import pydicom.data \n",
    "from pathlib import Path\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import time\n",
    "####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "####\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "##\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from PIL import Image\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009d993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>rad_ID</th>\n",
       "      <th>No finding</th>\n",
       "      <th>Bronchitis</th>\n",
       "      <th>Brocho-pneumonia</th>\n",
       "      <th>Other disease</th>\n",
       "      <th>Bronchiolitis</th>\n",
       "      <th>Situs inversus</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleuro-pneumonia</th>\n",
       "      <th>Diagphramatic hernia</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>Congenital emphysema</th>\n",
       "      <th>CPAM</th>\n",
       "      <th>Hyaline membrane disease</th>\n",
       "      <th>Mediastinal tumor</th>\n",
       "      <th>Lung tumor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6cb53aff85c71b98ad13d67a131708c6</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40414c05687cdb156823c156967b13f0</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e4a464dfbf8abc6333c82f1b77b6455</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4d3fab0b71381e6b237dc36301e85a0</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b58c9b1c89978a0b1f8533b7a2ca1088</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id rad_ID  No finding  Bronchitis  \\\n",
       "0  6cb53aff85c71b98ad13d67a131708c6     R3         0.0         0.0   \n",
       "1  40414c05687cdb156823c156967b13f0     R3         0.0         0.0   \n",
       "2  0e4a464dfbf8abc6333c82f1b77b6455     R3         0.0         0.0   \n",
       "3  f4d3fab0b71381e6b237dc36301e85a0     R3         0.0         0.0   \n",
       "4  b58c9b1c89978a0b1f8533b7a2ca1088     R3         0.0         0.0   \n",
       "\n",
       "   Brocho-pneumonia  Other disease  Bronchiolitis  Situs inversus  Pneumonia  \\\n",
       "0               0.0            0.0            0.0             0.0        1.0   \n",
       "1               0.0            0.0            1.0             0.0        0.0   \n",
       "2               0.0            0.0            1.0             0.0        0.0   \n",
       "3               0.0            0.0            1.0             0.0        0.0   \n",
       "4               0.0            1.0            0.0             0.0        0.0   \n",
       "\n",
       "   Pleuro-pneumonia  Diagphramatic hernia  Tuberculosis  Congenital emphysema  \\\n",
       "0               0.0                   0.0           0.0                   0.0   \n",
       "1               0.0                   0.0           0.0                   0.0   \n",
       "2               0.0                   0.0           0.0                   0.0   \n",
       "3               0.0                   0.0           0.0                   0.0   \n",
       "4               0.0                   0.0           0.0                   0.0   \n",
       "\n",
       "   CPAM  Hyaline membrane disease  Mediastinal tumor  Lung tumor  \n",
       "0   0.0                       0.0                0.0         0.0  \n",
       "1   0.0                       0.0                0.0         0.0  \n",
       "2   0.0                       0.0                0.0         0.0  \n",
       "3   0.0                       0.0                0.0         0.0  \n",
       "4   0.0                       0.0                0.0         0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df = pd.read_csv(Path('image_labels_train.csv'))\n",
    "\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49a903d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>oneVal</th>\n",
       "      <th>zeroVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No finding</td>\n",
       "      <td>5143</td>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>842</td>\n",
       "      <td>6886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brocho-pneumonia</td>\n",
       "      <td>545</td>\n",
       "      <td>7183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other disease</td>\n",
       "      <td>412</td>\n",
       "      <td>7316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bronchiolitis</td>\n",
       "      <td>497</td>\n",
       "      <td>7231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Situs inversus</td>\n",
       "      <td>11</td>\n",
       "      <td>7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>392</td>\n",
       "      <td>7336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pleuro-pneumonia</td>\n",
       "      <td>6</td>\n",
       "      <td>7722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Diagphramatic hernia</td>\n",
       "      <td>3</td>\n",
       "      <td>7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>14</td>\n",
       "      <td>7714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Congenital emphysema</td>\n",
       "      <td>2</td>\n",
       "      <td>7726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CPAM</td>\n",
       "      <td>5</td>\n",
       "      <td>7723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hyaline membrane disease</td>\n",
       "      <td>19</td>\n",
       "      <td>7709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mediastinal tumor</td>\n",
       "      <td>8</td>\n",
       "      <td>7720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lung tumor</td>\n",
       "      <td>5</td>\n",
       "      <td>7723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Label  oneVal  zeroVal\n",
       "0                 No finding    5143     2585\n",
       "1                 Bronchitis     842     6886\n",
       "2           Brocho-pneumonia     545     7183\n",
       "3              Other disease     412     7316\n",
       "4              Bronchiolitis     497     7231\n",
       "5             Situs inversus      11     7717\n",
       "6                  Pneumonia     392     7336\n",
       "7           Pleuro-pneumonia       6     7722\n",
       "8       Diagphramatic hernia       3     7725\n",
       "9               Tuberculosis      14     7714\n",
       "10      Congenital emphysema       2     7726\n",
       "11                      CPAM       5     7723\n",
       "12  Hyaline membrane disease      19     7709\n",
       "13         Mediastinal tumor       8     7720\n",
       "14                Lung tumor       5     7723"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['No finding', 'Bronchitis', 'Brocho-pneumonia',\n",
    "       'Other disease', 'Bronchiolitis', 'Situs inversus', 'Pneumonia', 'Pleuro-pneumonia',\n",
    "       'Diagphramatic hernia', 'Tuberculosis', 'Congenital emphysema', 'CPAM',\n",
    "       'Hyaline membrane disease', 'Mediastinal tumor','Lung tumor']\n",
    "\n",
    "\n",
    "data_df = []\n",
    "\n",
    "for i in cols:\n",
    "    oneVal = sum(np.where(full_train_df[i] == 1,1,0))\n",
    "    zeroVal = sum(np.where(full_train_df[i] == 0,1,0))\n",
    "    data_df.append([i,oneVal,zeroVal])\n",
    "    \n",
    "data_df = pd.DataFrame(data_df)\n",
    "data_df.columns = ['Label','oneVal','zeroVal']\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cac915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No finding', 'Bronchitis', 'Brocho-pneumonia', 'Other disease',\n",
       "       'Bronchiolitis', 'Situs inversus', 'Pneumonia', 'Pleuro-pneumonia',\n",
       "       'Diagphramatic hernia', 'Tuberculosis', 'Congenital emphysema', 'CPAM',\n",
       "       'Hyaline membrane disease', 'Mediastinal tumor', 'Lung tumor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = full_train_df.columns[2:]\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "370eb599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, num_classes=15, is_trained=False):\n",
    "        super().__init__()\n",
    "        self.ConvLayer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3), # inp (3, 512, 512)\n",
    "            nn.Conv2d(8, 16, 3),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU() # op (16, 256, 256)\n",
    "        )\n",
    "        self.ConvLayer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5), # inp (16, 256, 256)\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.ReLU() # op (32, 64, 64)\n",
    "        )\n",
    "        self.ConvLayer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3), # inp (32, 64, 64)\n",
    "            nn.Conv2d(64, 64, 5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU() # op (64, 32, 32)\n",
    "        )\n",
    "        self.ConvLayer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 5), # inp (64, 32, 32)\n",
    "            nn.Conv2d(128, 128, 3),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU() # op (128, 16, 16)\n",
    "        )\n",
    "        #self.Lin1 = nn.Linear(15488, 15)\n",
    "        self.Lin1 = nn.Sequential(nn.Linear(512, 15), nn.Sigmoid())        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ConvLayer1(x)\n",
    "        x = self.ConvLayer2(x)\n",
    "        x = self.ConvLayer3(x)\n",
    "        x = self.ConvLayer4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(x.size())\n",
    "        x = self.Lin1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00297700",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "###   ResNet18\n",
    "####################################################################################\n",
    "#\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=15, is_trained=False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.net = torchvision.models.resnet18(pretrained=is_trained)\n",
    "        # Get the input dimension of last layer\n",
    "        #kernel_count = self.net.classifier.in_features\n",
    "\n",
    "        ## Freeze first 8 layers\n",
    "        ct = 0\n",
    "        for child in self.net.children():\n",
    "            ct += 1\n",
    "            if ct < 9:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "                \n",
    "        # Replace last layer with new layer that have num_classes nodes, after that apply Sigmoid to the output\n",
    "        self.net.fc = nn.Sequential(\n",
    "               nn.Linear(512, 128),\n",
    "               nn.ReLU(inplace=True),\n",
    "               nn.Linear(128, 15),nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward the netword with the inputs\n",
    "        \"\"\"\n",
    "        return self.net(inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd93950",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, folder_dir, dataframe, transform):\n",
    "        \"\"\"\n",
    "        Init Dataset\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        folder_dir: str\n",
    "            folder contains all images\n",
    "        dataframe: pandas.DataFrame\n",
    "            dataframe contains all information of images\n",
    "        image_size: int\n",
    "            image size to rescale\n",
    "        normalization: bool\n",
    "            whether applying normalization with mean and std from ImageNet or not\n",
    "        \"\"\"\n",
    "        self.image_paths = [] # List of image paths\n",
    "        self.image_labels = [] # List of image labels\n",
    "        \n",
    "        # Define list of image transformations\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get all image paths and image labels from dataframe\n",
    "        for index, row in dataframe.iterrows():\n",
    "            image_path = folder_dir+str(row.image_id)+'.dicom'\n",
    "            self.image_paths.append(image_path)\n",
    "            labels = []\n",
    "            for col in row[2:]:\n",
    "                if col == 1:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "            self.image_labels.append(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         \"\"\"\n",
    "#         Read image at index and convert to torch Tensor\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Read image\n",
    "#         image_path = self.image_paths[index]\n",
    "# #         image_data = Image.open(image_path).convert(\"RGB\") # Convert image to RGB channels\n",
    "#         images_data = pydicom.dcmread(image_path)\n",
    "#         pil_image_data = Image.fromarray(images_data.pixel_array, mode=\"L\")\n",
    "#         image_data = pil_image_data.convert(\"RGB\")\n",
    "#         # TODO: Image augmentation code would be placed here\n",
    "        \n",
    "#         # Resize and convert image to torch tensor \n",
    "#         image_data = self.image_transformation(pil_image_data)\n",
    "        \n",
    "#         return image_data, torch.FloatTensor(self.image_labels[index])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Read image at index and convert to torch Tensor\n",
    "        \"\"\"\n",
    "        # Read image\n",
    "        image_path = self.image_paths[index]\n",
    "        \n",
    "        dataset = pydicom.dcmread(image_path, force=True)\n",
    "        pil_image_data = Image.fromarray(dataset.pixel_array, mode=\"L\")\n",
    "        \n",
    "        pil_image_data = pil_image_data.convert('RGB')\n",
    "        # TODO: Image augmentation code would be placed here\n",
    "\n",
    "        # Resize and convert image to torch tensor \n",
    "        image_data = self.transform(pil_image_data)\n",
    "        return image_data, torch.FloatTensor(self.image_labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13649bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224                              # Image size (224x224)\n",
    "BATCH_SIZE = 96                              \n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_SCHEDULE_FACTOR = 0.1           # Parameter used for reducing learning rate\n",
    "LEARNING_RATE_SCHEDULE_PATIENCE = 5           # Parameter used for reducing learning rate\n",
    "MAX_EPOCHS = 2 ##100                              # Maximum number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "287f6043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6182\n",
      "1546\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(full_train_df, test_size=0.20, random_state=2021)\n",
    "del full_train_df\n",
    "gc.collect()\n",
    "print(train_data.image_id.size)\n",
    "print(val_data.image_id.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83fb2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/HP/Desktop/Untitled Folder/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77aa9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    #Converting images to the size that the model expects\n",
    "    torchvision.transforms.Resize(size=(224,224)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(), #A RandomHorizontalFlip to augment our data\n",
    "    torchvision.transforms.ToTensor(), #Converting to tensor\n",
    "    torchvision.transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                                    std = [0.229, 0.224, 0.225]) #Normalizing the data to the data that the ResNet18 was trained on\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5b5c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training batches 65\n"
     ]
    }
   ],
   "source": [
    "my_data_path = path\n",
    "train_dataset = ChestXrayDataset(my_data_path, train_data, train_transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Num of training batches', len(train_dataloader))\n",
    "# for data, label in train_dataloader:\n",
    "#     print(data.size())\n",
    "#     print(label.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ca9a8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcd1f392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of training batches 17\n"
     ]
    }
   ],
   "source": [
    "val_dataset = ChestXrayDataset(my_data_path, val_data, train_transform)\n",
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print('Num of training batches', len(val_dataloader))\n",
    "# for data, label in val_dataloader:\n",
    "#     print(data.size())\n",
    "#     print(label.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3a9768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data\n",
    "del val_data\n",
    "del train_dataset\n",
    "del val_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb42d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_auroc(y_gt, y_pred):\n",
    "    \"\"\" Calculate AUROC for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    auroc = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        try:\n",
    "            auroc.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return auroc\n",
    "\n",
    "def multi_label_accuracy(y_gt, y_pred):\n",
    "    \"\"\" Calculate AUROC for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        acc.append(accuracy_score(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0)))\n",
    "    return acc\n",
    "\n",
    "def multi_label_f1(y_gt, y_pred):\n",
    "    \"\"\" Calculate f1 for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        F1 of each class\n",
    "    \"\"\"\n",
    "    f1_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        f1_out.append(f1_score(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0)))\n",
    "    return f1_out\n",
    "\n",
    "\n",
    "def multi_label_precision_recall(y_gt, y_pred):\n",
    "    \"\"\" Calculate precision for each class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_gt: torch.Tensor\n",
    "        groundtruth\n",
    "    y_pred: torch.Tensor\n",
    "        prediction\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        precision of each class\n",
    "    \"\"\"\n",
    "    precision_out = []\n",
    "    recall_out = []\n",
    "    gt_np = y_gt.to(\"cpu\").numpy()\n",
    "    pred_np = y_pred.to(\"cpu\").numpy()\n",
    "    assert gt_np.shape == pred_np.shape, \"y_gt and y_pred should have the same size\"\n",
    "    for i in range(gt_np.shape[1]):\n",
    "        p = precision_recall_fscore_support(gt_np[:, i], np.where(pred_np[:, i]>=0.5,1,0),average='binary')\n",
    "        precision_out.append(p[0])\n",
    "        recall_out.append(p[1])\n",
    "    return precision_out,recall_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f1a3578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb):\n",
    "    \"\"\"\n",
    "    Epoch training\n",
    "\n",
    "    Paramteters\n",
    "    -----------\n",
    "    epoch: int\n",
    "      epoch number\n",
    "    model: torch Module\n",
    "      model to train\n",
    "    train_dataloader: Dataset\n",
    "      data loader for training\n",
    "    device: str\n",
    "      \"cpu\" or \"cuda\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    optimizer: torch optimizer\n",
    "      optimizer used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "      training loss\n",
    "    \"\"\"\n",
    "    # Switch model to training mode\n",
    "    model.train()\n",
    "    training_loss = 0 # Storing sum of training losses\n",
    "        # For each batch\n",
    "    for batch, (images, labels) in enumerate(progress_bar(train_dataloader, parent=mb)):\n",
    "        \n",
    "        # Move X, Y  to device (GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Clear previous gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Feed forward the model\n",
    "        pred = model(images)\n",
    "        #pred = torch.LongTensor(pred)\n",
    "        loss = loss_criteria(pred, labels)\n",
    "        #print(\"loss is \",loss)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update training loss after each batch\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        #mb.child.comment = f'Training loss {training_loss/(batch+1)}'\n",
    "\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "\n",
    "    # return training loss\n",
    "    return training_loss/len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "633e5c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluating(epoch, model, val_loader, device, loss_criteria, mb):\n",
    "    \"\"\"\n",
    "    Validate model on validation dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch: int\n",
    "        epoch number\n",
    "    model: torch Module\n",
    "        model used for validation\n",
    "    val_loader: Dataset\n",
    "        data loader of validation set\n",
    "    device: str\n",
    "        \"cuda\" or \"cpu\"\n",
    "    loss_criteria: loss function\n",
    "      loss function used for training\n",
    "    mb: master bar of fastprogress\n",
    "      progress to log\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        loss on validation set\n",
    "    float\n",
    "        metric score on validation set\n",
    "    \"\"\"\n",
    " \n",
    "    # Switch model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    val_loss = 0                                   # Total loss of model on validation set\n",
    "    out_pred = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    out_gt = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    \n",
    "    with torch.no_grad(): # Turn off gradient\n",
    "        # For each batch\n",
    "        for step, (images, labels) in enumerate(progress_bar(val_loader, parent=mb)):\n",
    "            # Move images, labels to device (GPU)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Update groundtruth values\n",
    "            out_gt = torch.cat((out_gt,  labels), 0)\n",
    "            \n",
    "            # Feed forward the model\n",
    "            ps = model(images)\n",
    "            loss = loss_criteria(ps, labels)\n",
    "\n",
    "            # Update prediction values\n",
    "            out_pred = torch.cat((out_pred, ps), 0)\n",
    "\n",
    "            # Update validation loss after each batch\n",
    "            val_loss += loss\n",
    "            #mb.child.comment = f'Validation loss {val_loss/(step+1)}'\n",
    "\n",
    "    # Clear memory\n",
    "    del images, labels, loss\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    # return validation loss, and metric score\n",
    "    val_loss_mean = val_loss/len(val_loader)\n",
    "    auroc_mean = np.nanmean(np.array(multi_label_auroc(out_gt, out_pred)))\n",
    "    acc_mean = np.nanmean(np.array(multi_label_accuracy(out_gt, out_pred)))\n",
    "    f1_mean = np.nanmean(np.array(multi_label_f1(out_gt, out_pred)))\n",
    "    \n",
    "    print('accuracy_mean = {}, f1_mean = {} ',acc_mean,f1_mean)\n",
    "    \n",
    "    return val_loss_mean,auroc_mean,acc_mean,f1_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93aac890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opt(modeltxt,model):\n",
    "    \n",
    "    if modeltxt == \"ResNet18\":\n",
    "        return optim.Adam(model.parameters())\n",
    "    \n",
    "    if modeltxt == \"CustomNet\":\n",
    "        return optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb61f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(modelname,loss_criteria,modeltxt):\n",
    "    model = modelname(num_classes=len(LABELS),is_trained=True).to(device)\n",
    "\n",
    "    optimizer = get_opt(modeltxt,model)\n",
    "    # Learning rate will be reduced automatically during training\n",
    "    lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = LEARNING_RATE_SCHEDULE_FACTOR,\n",
    "                                                        patience = LEARNING_RATE_SCHEDULE_PATIENCE, mode = 'max', verbose=True)\n",
    "    best_score = 0\n",
    "    best_score_acc = 0\n",
    "    best_score_f1 = 0\n",
    "    modeltxt = r\"\\resnet18\"\n",
    "    \n",
    "    model_path = out+modeltxt+\".pth\"\n",
    "    out_path = out+modeltxt+\"_running.csv\"\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    validation_score = []\n",
    "    validation_acc = []\n",
    "    validation_f1 = []\n",
    "\n",
    "\n",
    "    # Config progress bar\n",
    "    mb = master_bar(range(MAX_EPOCHS))\n",
    "    mb.names = ['Train loss', 'Val loss', 'AUROC', 'Accuracy', 'f1 score']\n",
    "    x = []\n",
    "\n",
    "    nonimproved_epoch = 0\n",
    "    start_time = time.time()\n",
    "    cnt = 1\n",
    "    # Training each epoch\n",
    "    for epoch in mb:\n",
    "        #break\n",
    "        mb.main_bar.comment = f'Best AUROC score: {best_score}'\n",
    "        x.append(epoch)\n",
    "\n",
    "        # Training\n",
    "        train_loss = epoch_training(epoch, model, train_dataloader, device, loss_criteria, optimizer, mb)\n",
    "        mb.write('Finish training epoch {} with loss {:.4f}'.format(epoch, train_loss))\n",
    "        training_losses.append(train_loss)\n",
    "\n",
    "        # Evaluating\n",
    "        mb.write('evualuate')\n",
    "        val_loss, new_score, new_score_acc, new_score_f1 = evaluating(epoch, model, val_dataloader, device, loss_criteria, mb)\n",
    "\n",
    "        validation_losses.append(val_loss)\n",
    "        validation_score.append(new_score)\n",
    "        validation_acc.append(new_score_acc)\n",
    "        validation_f1.append(new_score_f1)\n",
    "\n",
    "        gc.collect()\n",
    "        # Update learning rate\n",
    "        lr_scheduler.step(new_score)\n",
    "\n",
    "        # Update training chart\n",
    "        mb.update_graph([[x, training_losses], [x, validation_losses], [x, validation_score] , [x, validation_acc] ,\n",
    "                         [x, validation_f1]],\n",
    "                        [0,epoch+1+round(epoch*0.3)], [0,1])\n",
    "\n",
    "        diff = np.round(time.time() - start_time)\n",
    "        pd.DataFrame([[epoch,modeltxt,best_score,new_score,diff]]).to_csv(out_path,index=False,mode='a',header=False)\n",
    "        # Save model\n",
    "        t2 = 4\n",
    "        if best_score < new_score:\n",
    "            #mb.write(f\"Improve AUROC from {best_score} to {new_score}\")    \n",
    "            best_score = new_score\n",
    "            best_score_acc = new_score_acc\n",
    "            best_score_f1 = new_score_f1\n",
    "            nonimproved_epoch = 0\n",
    "            best_model = model\n",
    "            torch.save({\"model\": model.state_dict(), \n",
    "                        \"optimizer\": optimizer.state_dict(), \n",
    "                        \"best_score\": best_score, \n",
    "                        \"epoch\": epoch, \n",
    "                        \"lr_scheduler\": lr_scheduler.state_dict()}, model_path)\n",
    "        else: \n",
    "            nonimproved_epoch += 1\n",
    "        if nonimproved_epoch > 5:\n",
    "            break\n",
    "            print(\"Early stopping\")\n",
    "        if time.time() - start_time > 3600*t2:\n",
    "            break\n",
    "            print(\"Out of time\")\n",
    "\n",
    "    \n",
    "    return best_score,best_score_acc,best_score_f1,best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb41f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [CustomNet,ResNet18]\n",
    "mName_list = ['CustomNet','ResNet18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c76a2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# Define the model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Define the path where you want to save the model\n",
    "save_path = r'C:\\Users\\HP\\Desktop\\Untitled Folder\\models'+r'\\ResNet18.pth'  # Replace 'path_to_your_folder' with the actual folder path\n",
    "\n",
    "# Save the model state dictionary to the specified path\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "out = r'C:\\Users\\HP\\Desktop\\Untitled Folder\\models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c10aa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5900e314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model ResNet18 with focal loss function\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finish training epoch 0 with loss 0.1836<p>evualuate<p>Finish training epoch 1 with loss 0.1724<p>evualuate"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_mean = {}, f1_mean = {}  0.9314359637774902 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_mean = {}, f1_mean = {}  0.9313928417421302 0.0\n"
     ]
    }
   ],
   "source": [
    "eval_df_train = []\n",
    "# for m in model_list:\n",
    "#     mName = m().__class__.__name__\n",
    "#     print(\"Processing Model \",mName)\n",
    "#     globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"],globals()[f\"best_model_{mName}\"] = trainModel(modelname=m,loss_criteria=nn.BCELoss(),modeltxt=mName)\n",
    "#     eval_df_train.append([mName,globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"]])\n",
    "    \n",
    "model_List2 = [ResNet18]\n",
    "for m in model_List2: \n",
    "    mName = m().__class__.__name__\n",
    "    print(\"Processing Model ResNet18 with focal loss function\")\n",
    "    globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"],globals()[f\"best_model_{mName}\"] = trainModel(modelname=m,loss_criteria=FocalLoss(alpha=1, gamma=2, reduction='mean'),modeltxt=mName)\n",
    "    eval_df_train.append([mName,globals()[f\"best_score_{mName}\"],globals()[f\"best_score_acc_{mName}\"],globals()[f\"best_score_f1_{mName}\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb635a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_train=pd.DataFrame(eval_df_train)\n",
    "eval_df_train.columns = ['Model Name','AUROC', 'Accuracy', 'f1 Score']\n",
    "eval_df_train.to_csv(out+\"eval_df_train.csv\",index=False)\n",
    "eval_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "276967a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Total Parameters</th>\n",
       "      <th>Trainable Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>11244111</td>\n",
       "      <td>67599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Total Parameters  Trainable Parameters\n",
       "0   ResNet18          11244111                 67599"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def count_parameters_all(model):\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "param_list = []\n",
    "i = 0\n",
    "for model in model_list:\n",
    "    modelName = model().__class__.__name__\n",
    "    num_params_all = count_parameters_all(model())\n",
    "    num_params = count_parameters(model())\n",
    "    param_list.append([modelName,num_params_all,num_params])\n",
    "\n",
    "param_list=pd.DataFrame(param_list)\n",
    "param_list.columns = ['Model Name','Total Parameters','Trainable Parameters']\n",
    "param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5471a582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6499"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_dataloader\n",
    "del val_dataloader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f256771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/HP/Desktop/Untitled Folder/'\n",
    "full_test_df = pd.read_csv(path+'image_labels_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c9c31a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23749"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e8a931c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 15])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "my_data_path = r'C:/Users/HP/Desktop/Untitled Folder/test/'\n",
    "test_dataset = ChestXrayDataset(my_data_path, full_test_df, train_transform)\n",
    "#test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "for data, label in test_dataloader:\n",
    "    print(data.size())\n",
    "    print(label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da2e5328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_dataset\n",
    "del full_test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9d52060",
   "metadata": {},
   "outputs": [],
   "source": [
    " def getTestPreds(best_model,test_dataloader,modeltxt):\n",
    "    y_pred_t = torch.FloatTensor().to(device)      # Tensor stores prediction values\n",
    "    y_test_t = torch.FloatTensor().to(device)        # Tensor stores groundtruth values\n",
    "\n",
    "    y_pred_list = []\n",
    "    y_test_list = []\n",
    "\n",
    "    test_auroc = []\n",
    "    test_acc = []\n",
    "    test_f1 = []\n",
    "    test_precision = []\n",
    "    test_recall = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        best_model.eval()\n",
    "        for X_batch, labels in test_dataloader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            ps = best_model(X_batch)\n",
    "\n",
    "            y_test_t = torch.cat((y_test_t,  labels), 0)\n",
    "            y_pred_t = torch.cat((y_pred_t, ps), 0)\n",
    "            \n",
    "            test_acc.append(np.mean(multi_label_accuracy(y_test_t, y_pred_t)))\n",
    "            test_f1.append(np.mean(multi_label_f1(y_test_t, y_pred_t)))\n",
    "            test_auroc.append(np.mean(multi_label_auroc(y_test_t, y_pred_t)))\n",
    "            \n",
    "            p,r = multi_label_precision_recall(y_test_t, y_pred_t)\n",
    "            test_precision.append(np.mean(p))\n",
    "            test_recall.append(np.mean(r))\n",
    "        \n",
    "        test_auroc = np.nanmean(test_auroc)\n",
    "        test_acc = np.nanmean(test_acc)\n",
    "        test_f1 = np.nanmean(test_f1)\n",
    "        test_precision = np.nanmean(test_precision)\n",
    "        test_recall = np.nanmean(test_recall)\n",
    "        \n",
    "        print(\"AUROC : \",test_auroc)\n",
    "        print(\"Accuracy : \",test_acc)\n",
    "        print(\"f1 score : \",test_f1)\n",
    "        print(\"precision score : \",test_precision)\n",
    "        print(\"recall score : \",test_recall)\n",
    "        \n",
    "        eval_matrix = [modeltxt,test_auroc,test_acc,test_f1,test_precision,test_recall]\n",
    "        \n",
    "        return y_test_t,y_pred_t,eval_matrix\n",
    "\n",
    "############## Plot\n",
    "def plot_conf(y_test,y_pred,modeltxt):\n",
    "    f, axes = plt.subplots(2, 7, figsize=(25, 8))\n",
    "    f.suptitle('Confustion Matrix For Model '+ modeltxt, fontsize=20, fontweight='bold')\n",
    "    plt.rcParams.update({'font.size': 14,'font.weight': 'bold'})\n",
    "    y_test = y_test.cpu()\n",
    "    y_pred = np.where(y_pred.cpu()>0.5,1,0)\n",
    "    axes = axes.ravel()\n",
    "    for i in range(14):\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix(y_test[:, i],\n",
    "                                                       y_pred[:, i]))\n",
    "        disp.plot(ax=axes[i], values_format='.10g')\n",
    "        disp.ax_.set_title(f'{LABELS[i]}')\n",
    "        disp.im_.colorbar.remove()\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.25, hspace=0.25)\n",
    "    plt.show()\n",
    "    \n",
    "################# Get Values\n",
    "\n",
    "def get_conf(y_test,y_pred,modeltxt):\n",
    "    conf_vals = []\n",
    "    y_test = y_test.cpu()\n",
    "    y_pred = np.where(y_pred.cpu()>0.5,1,0)\n",
    "    for i in range(15):\n",
    "        c = confusion_matrix(y_test[:, i],y_pred[:, i])\n",
    "        #p = c[0][0]\n",
    "        #q = c[0][1]\n",
    "        #r = c[1][0]\n",
    "       # s = c[1][1]\n",
    "        try:\n",
    "            p = c[0][0]\n",
    "        except IndexError:\n",
    "            p = 0\n",
    "\n",
    "        try:\n",
    "            q = c[0][1]\n",
    "        except IndexError:\n",
    "            q = 0\n",
    "            \n",
    "        try:\n",
    "            r = c[1][0]\n",
    "        except IndexError:\n",
    "            r = 0\n",
    "            \n",
    "        try:\n",
    "            s = c[1][1]\n",
    "        except IndexError:\n",
    "            s = 0\n",
    "        \n",
    "        conf_vals.append([modeltxt,LABELS[i],p,q,r,s])\n",
    "\n",
    "    return conf_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc192a8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'best_model_resnet18'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-e5600e4f5767>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf\"best_model_{mName}\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'best_model_resnet18'"
     ]
    }
   ],
   "source": [
    "globals()[f\"best_model_{mName}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "50c939e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for Model  ResNet18\n",
      "AUROC :  0.5507192569300474\n",
      "Accuracy :  0.9141492574030546\n",
      "f1 score :  0.02416237294205977\n",
      "precision score :  0.020644886776518462\n",
      "recall score :  0.03231484050088187\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eval_matrix_all = []\n",
    "for mName in mName_list:\n",
    "    print(\"Predicting for Model \",mName)\n",
    "    globals()[f\"y_test_t_{mName}\"],globals()[f\"y_pred_t_{mName}\"],eval_matrix = getTestPreds(globals()[f\"best_model_{mName}\"],test_dataloader,mName)\n",
    "    eval_matrix_all.append(eval_matrix)\n",
    "    print(\"----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bd676e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Label</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>No finding</td>\n",
       "      <td>0.624195</td>\n",
       "      <td>0.694106</td>\n",
       "      <td>0.753032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Bronchitis</td>\n",
       "      <td>0.875447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Brocho-pneumonia</td>\n",
       "      <td>0.939871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Other disease</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Bronchiolitis</td>\n",
       "      <td>0.935576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Situs inversus</td>\n",
       "      <td>0.998568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>0.936292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Pleuro-pneumonia</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Diagphramatic hernia</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Tuberculosis</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Congenital emphysema</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>CPAM</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Hyaline membrane disease</td>\n",
       "      <td>0.997853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Mediastinal tumor</td>\n",
       "      <td>0.999284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ResNet18</td>\n",
       "      <td>Lung tumor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name                     Label  Accuracy  Precision    Recall\n",
       "0    ResNet18                No finding  0.624195   0.694106  0.753032\n",
       "1    ResNet18                Bronchitis  0.875447   0.000000  0.000000\n",
       "2    ResNet18          Brocho-pneumonia  0.939871   0.000000  0.000000\n",
       "3    ResNet18             Other disease  0.944882   0.000000  0.000000\n",
       "4    ResNet18             Bronchiolitis  0.935576   0.000000  0.000000\n",
       "5    ResNet18            Situs inversus  0.998568   0.000000  0.000000\n",
       "6    ResNet18                 Pneumonia  0.936292   0.000000  0.000000\n",
       "7    ResNet18          Pleuro-pneumonia  1.000000   0.000000  0.000000\n",
       "8    ResNet18      Diagphramatic hernia  1.000000   0.000000  0.000000\n",
       "9    ResNet18              Tuberculosis  0.999284   0.000000  0.000000\n",
       "10   ResNet18      Congenital emphysema  1.000000   0.000000  0.000000\n",
       "11   ResNet18                      CPAM  0.999284   0.000000  0.000000\n",
       "12   ResNet18  Hyaline membrane disease  0.997853   0.000000  0.000000\n",
       "13   ResNet18         Mediastinal tumor  0.999284   0.000000  0.000000\n",
       "14   ResNet18                Lung tumor  1.000000   0.000000  0.000000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list_all = []\n",
    "for mName in mName_list:\n",
    "    #print(\"Model \",mName)\n",
    "    for i in range(15):\n",
    "        acc = accuracy_score(globals()[f\"y_test_t_{mName}\"].to(\"cpu\").numpy()[:, i], np.where(globals()[f\"y_pred_t_{mName}\"].to(\"cpu\").numpy()[:, i]>=0.5,1,0))\n",
    "        p = precision_recall_fscore_support(globals()[f\"y_test_t_{mName}\"].to(\"cpu\").numpy()[:, i], np.where(globals()[f\"y_pred_t_{mName}\"].to(\"cpu\").numpy()[:, i]>=0.5,1,0),average='binary')\n",
    "        #print(LABELS[i],\" ==> \",\"Acc : \",acc,\" Precision : \",p[0],\" Recall : \",p[1])  \n",
    "        \n",
    "        #print(LABELS[i],p)\n",
    "        label_list_all.append([mName,LABELS[i],acc,p[0],p[1]])\n",
    "    \n",
    "\n",
    "df_label_list_all = pd.DataFrame(label_list_all)\n",
    "df_label_list_all.columns = [\"Model Name\",\"Label\",\"Accuracy\",\"Precision\",\"Recall\"]\n",
    "df_label_list_all.to_csv(out+\"df_label_list_all.csv\",index=False)\n",
    "df_label_list_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21028303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
