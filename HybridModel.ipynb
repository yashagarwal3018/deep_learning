{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eba1d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt \n",
    "import pydicom \n",
    "import pydicom.data \n",
    "from pathlib import Path\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import time\n",
    "####\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "####\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "##\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f835d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>rad_ID</th>\n",
       "      <th>No finding</th>\n",
       "      <th>Bronchitis</th>\n",
       "      <th>Brocho-pneumonia</th>\n",
       "      <th>Other disease</th>\n",
       "      <th>Bronchiolitis</th>\n",
       "      <th>Situs inversus</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Pleuro-pneumonia</th>\n",
       "      <th>Diagphramatic hernia</th>\n",
       "      <th>Tuberculosis</th>\n",
       "      <th>Congenital emphysema</th>\n",
       "      <th>CPAM</th>\n",
       "      <th>Hyaline membrane disease</th>\n",
       "      <th>Mediastinal tumor</th>\n",
       "      <th>Lung tumor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6cb53aff85c71b98ad13d67a131708c6</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40414c05687cdb156823c156967b13f0</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0e4a464dfbf8abc6333c82f1b77b6455</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f4d3fab0b71381e6b237dc36301e85a0</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b58c9b1c89978a0b1f8533b7a2ca1088</td>\n",
       "      <td>R3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id rad_ID  No finding  Bronchitis  \\\n",
       "0  6cb53aff85c71b98ad13d67a131708c6     R3         0.0         0.0   \n",
       "1  40414c05687cdb156823c156967b13f0     R3         0.0         0.0   \n",
       "2  0e4a464dfbf8abc6333c82f1b77b6455     R3         0.0         0.0   \n",
       "3  f4d3fab0b71381e6b237dc36301e85a0     R3         0.0         0.0   \n",
       "4  b58c9b1c89978a0b1f8533b7a2ca1088     R3         0.0         0.0   \n",
       "\n",
       "   Brocho-pneumonia  Other disease  Bronchiolitis  Situs inversus  Pneumonia  \\\n",
       "0               0.0            0.0            0.0             0.0        1.0   \n",
       "1               0.0            0.0            1.0             0.0        0.0   \n",
       "2               0.0            0.0            1.0             0.0        0.0   \n",
       "3               0.0            0.0            1.0             0.0        0.0   \n",
       "4               0.0            1.0            0.0             0.0        0.0   \n",
       "\n",
       "   Pleuro-pneumonia  Diagphramatic hernia  Tuberculosis  Congenital emphysema  \\\n",
       "0               0.0                   0.0           0.0                   0.0   \n",
       "1               0.0                   0.0           0.0                   0.0   \n",
       "2               0.0                   0.0           0.0                   0.0   \n",
       "3               0.0                   0.0           0.0                   0.0   \n",
       "4               0.0                   0.0           0.0                   0.0   \n",
       "\n",
       "   CPAM  Hyaline membrane disease  Mediastinal tumor  Lung tumor  \n",
       "0   0.0                       0.0                0.0         0.0  \n",
       "1   0.0                       0.0                0.0         0.0  \n",
       "2   0.0                       0.0                0.0         0.0  \n",
       "3   0.0                       0.0                0.0         0.0  \n",
       "4   0.0                       0.0                0.0         0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df = pd.read_csv(Path('image_labels_train.csv'))\n",
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df1b45e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7728/7728 [11:01<00:00, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7728, 32, 32, 3) - y_train shape: (7728, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes = 15\n",
    "\n",
    "# Load the CSV file containing image labels\n",
    "full_train_df = pd.read_csv('image_labels_train.csv')\n",
    "\n",
    "# Create an empty list for image data and labels\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# Specify the folder directory containing the image files\n",
    "folder_dir = 'C:/Users/HP/Desktop/Untitled Folder/train/'\n",
    "\n",
    "# Define a transform to preprocess the images (adjust this as needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32 pixels\n",
    "    transforms.ToTensor()  # Convert to a torch tensor\n",
    "])\n",
    "\n",
    "# Get all image paths and image labels from the dataframe\n",
    "for index, row in tqdm(full_train_df.iterrows(), total=len(full_train_df)):\n",
    "    image_path = folder_dir + str(row.image_id) + '.dicom'\n",
    "    dataset = pydicom.dcmread(image_path, force=True)\n",
    "    pil_image_data = Image.fromarray(dataset.pixel_array, mode=\"L\")\n",
    "    \n",
    "    pil_image_data = pil_image_data.convert('RGB')\n",
    "    \n",
    "    # Apply the defined transform to the image\n",
    "    image_data = transform(pil_image_data)\n",
    "    x_train.append(image_data)\n",
    "    \n",
    "    # Create one-hot encoded labels for each class\n",
    "    label = 2\n",
    "    for col in row[2:]:\n",
    "        if col == 1:\n",
    "            label = col\n",
    "            break\n",
    "    y_train.append(label)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train = np.stack(x_train, axis=0)\n",
    "y_train = np.array(y_train, dtype=int)\n",
    "\n",
    "# Reshape the labels to match Keras format\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "x_train = x_train.reshape(x_train.shape[0],32,32,3)\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0c538dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1397/1397 [02:06<00:00, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test shape: (1397, 32, 32, 3) - y_test shape: (1397, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_classes = 15\n",
    "\n",
    "# Load the CSV file containing image labels\n",
    "full_test_df = pd.read_csv('image_labels_test.csv')\n",
    "\n",
    "# Create an empty list for image data and labels\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "# Specify the folder directory containing the image files\n",
    "folder_dir = 'C:/Users/HP/Desktop/Untitled Folder/test/'\n",
    "\n",
    "# Define a transform to preprocess the images (adjust this as needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32 pixels\n",
    "    transforms.ToTensor()  # Convert to a torch tensor\n",
    "])\n",
    "\n",
    "# Get all image paths and image labels from the dataframe\n",
    "for index, row in tqdm(full_test_df.iterrows(), total=len(full_test_df)):\n",
    "    image_path = folder_dir + str(row.image_id) + '.dicom'\n",
    "    dataset = pydicom.dcmread(image_path, force=True)\n",
    "    pil_image_data = Image.fromarray(dataset.pixel_array, mode=\"L\")\n",
    "    \n",
    "    pil_image_data = pil_image_data.convert('RGB')\n",
    "    \n",
    "    # Apply the defined transform to the image\n",
    "    image_data = transform(pil_image_data)\n",
    "    x_test.append(image_data)\n",
    "    \n",
    "    # Create one-hot encoded labels for each class\n",
    "    label = 2\n",
    "    for col in row[2:]:\n",
    "        if col == 1:\n",
    "            label = col\n",
    "            break\n",
    "    y_test.append(label)\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_test = np.stack(x_test, axis=0)\n",
    "y_test = np.array(y_test, dtype=int)\n",
    "\n",
    "# Reshape the labels to match Keras format\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0],32,32,3)\n",
    "\n",
    "# Print the shapes of the loaded data\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6feaebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.21.0-cp38-cp38-win_amd64.whl (729 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-addons) (20.9)\n",
      "Collecting typeguard<3.0.0,>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->tensorflow-addons) (2.4.7)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.21.0 typeguard-2.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d74bae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 15\n",
    "input_shape = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "646a73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0cfd8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.02),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Setting the state of the normalization layer.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4db012cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dl-encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 32, 32, 3)         7         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23564807 (89.89 MB)\n",
      "Trainable params: 23519360 (89.72 MB)\n",
      "Non-trainable params: 45447 (177.53 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_encoder():\n",
    "    resnet = keras.applications.ResNet50V2(\n",
    "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
    "    )\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    augmented = data_augmentation(inputs)\n",
    "    outputs = resnet(augmented)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"dl-encoder\")\n",
    "    return model\n",
    "\n",
    "\n",
    "encoder = create_encoder()\n",
    "encoder.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "hidden_units = 512\n",
    "projection_units = 128\n",
    "num_epochs = 10\n",
    "dropout_rate = 0.5\n",
    "temperature = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4de85be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier(encoder, trainable=True):\n",
    "\n",
    "    for layer in encoder.layers:\n",
    "        layer.trainable = trainable\n",
    "\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
    "    features = layers.Dropout(dropout_rate)(features)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"dl-classifier\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cac804cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dl-classifier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " dl-encoder (Functional)     (None, 2048)              23564807  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 512)               1049088   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 15)                7695      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24621590 (93.92 MB)\n",
      "Trainable params: 24576143 (93.75 MB)\n",
      "Non-trainable params: 45447 (177.53 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 190s 2s/step - loss: 0.1727 - sparse_categorical_accuracy: 0.9811\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 173s 2s/step - loss: 0.0872 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 176s 2s/step - loss: 0.0552 - sparse_categorical_accuracy: 0.9928\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 340s 4s/step - loss: 0.0510 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 169s 2s/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 162s 2s/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 160s 2s/step - loss: 0.0809 - sparse_categorical_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 160s 2s/step - loss: 0.0472 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 159s 2s/step - loss: 0.0468 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 161s 2s/step - loss: 0.0456 - sparse_categorical_accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "classifier = create_classifier(encoder)\n",
    "classifier.summary()\n",
    "\n",
    "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6040705e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 4s 74ms/step - loss: 0.0500 - sparse_categorical_accuracy: 0.9928\n",
      "Test accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e065127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
    "    def __init__(self, temperature=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
    "        # Normalize feature vectors\n",
    "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
    "        # Compute logits\n",
    "        logits = tf.divide(\n",
    "            tf.matmul(\n",
    "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
    "            ),\n",
    "            self.temperature,\n",
    "        )\n",
    "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
    "\n",
    "\n",
    "def add_projection_head(encoder):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    features = encoder(inputs)\n",
    "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
    "    model = keras.Model(\n",
    "        inputs=inputs, outputs=outputs, name=\"dl-encoder_with_projection-head\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "129c3a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dl-encoder_with_projection-head\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " dl-encoder (Functional)     (None, 2048)              23564807  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               262272    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23827079 (90.89 MB)\n",
      "Trainable params: 23781632 (90.72 MB)\n",
      "Non-trainable params: 45447 (177.53 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "78/78 [==============================] - 174s 2s/step - loss: 4.6817\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 165s 2s/step - loss: 4.6003\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 163s 2s/step - loss: 4.6004\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 163s 2s/step - loss: 4.6003\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 163s 2s/step - loss: 4.6003\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 163s 2s/step - loss: 4.6004\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 164s 2s/step - loss: 4.6004\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 164s 2s/step - loss: 4.6004\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 163s 2s/step - loss: 4.6003\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 164s 2s/step - loss: 4.6003\n"
     ]
    }
   ],
   "source": [
    "encoder = create_encoder()\n",
    "\n",
    "encoder_with_projection_head = add_projection_head(encoder)\n",
    "encoder_with_projection_head.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),\n",
    "    loss=SupervisedContrastiveLoss(temperature),\n",
    ")\n",
    "\n",
    "encoder_with_projection_head.summary()\n",
    "\n",
    "history = encoder_with_projection_head.fit(\n",
    "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf60efb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 15s 164ms/step - loss: 0.2609 - sparse_categorical_accuracy: 0.9801\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 13s 164ms/step - loss: 0.1643 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 13s 164ms/step - loss: 0.1302 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 13s 166ms/step - loss: 0.2459 - sparse_categorical_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 13s 163ms/step - loss: 0.2024 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 13s 165ms/step - loss: 0.1439 - sparse_categorical_accuracy: 0.9926\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 13s 165ms/step - loss: 0.1003 - sparse_categorical_accuracy: 0.9926\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 13s 164ms/step - loss: 0.1525 - sparse_categorical_accuracy: 0.9929\n",
      "Epoch 9/10\n",
      "78/78 [==============================] - 13s 168ms/step - loss: 0.1964 - sparse_categorical_accuracy: 0.9930\n",
      "Epoch 10/10\n",
      "78/78 [==============================] - 13s 164ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "classifier = create_classifier(encoder, trainable=False)\n",
    "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6886e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 4s 74ms/step - loss: 1.6782 - sparse_categorical_accuracy: 0.9928\n",
      "Test accuracy: 99.28%\n"
     ]
    }
   ],
   "source": [
    "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
    "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adee59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
